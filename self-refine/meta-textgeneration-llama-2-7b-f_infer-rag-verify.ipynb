{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e38dbf5",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart - invoke text generation endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a8199",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to attach a predictor to an existing endpoint name and invoke the endpoint with example payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5c0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import retrieve_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9ae5d",
   "metadata": {},
   "source": [
    "Retrieve a predictor from your deployed endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab161cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"jumpstart-dft-meta-textgeneration-l-20240428-043847\"\n",
    "predictor = retrieve_default(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b60a1a",
   "metadata": {},
   "source": [
    "Now query your endpoint with example payloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf5bc0",
   "metadata": {},
   "source": [
    "This model supports the following payload parameters. You may specify any subset of these parameters when invoking an endpoint.\n",
    "\n",
    "* **do_sample:** If True, activates logits sampling. If specified, it must be boolean.\n",
    "* **max_new_tokens:** Maximum number of generated tokens. If specified, it must be a positive integer.\n",
    "* **repetition_penalty:** A penalty for repetitive generated text. 1.0 means no penalty.\n",
    "* **return_full_text:** If True, input text will be part of the output generated text. If specified, it must be boolean. The default value for it is False.\n",
    "* **stop**: If specified, it must a list of strings. Text generation stops if any one of the specified strings is generated.\n",
    "* **seed**: Random sampling seed.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **truncate:** Truncate inputs tokens to the given size.\n",
    "* **typical_p:** Typical decoding mass, according to [Typical Decoding for Natural Language Generation](https://arxiv.org/abs/2202.00666).\n",
    "* **best_of:** Generate best_of sequences and return the one if the highest token logprobs.\n",
    "* **watermark:** Whether to perform watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226).\n",
    "* **details:** Return generation details, to include output token logprobs and IDs.\n",
    "* **decoder_input_details:** Return decoder input token logprobs and IDs.\n",
    "* **top_n_tokens:** Return the N most likely tokens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6ccecc-012b-4d64-854d-c9d5b37e8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "from statistics import mean\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d452474e-1e38-45dd-b4aa-bf074718a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"gsm8k\", \"main\", ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7435d489-28b8-4946-b2af-fe2da15b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataset['train']\n",
    "data_test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff48e42-288a-48d5-85d7-375389d676a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(data=None):\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    for datum in data:\n",
    "        questions.append(datum[\"question\"].strip())\n",
    "        answers.append(datum[\"answer\"].split(\"#### \")[-1]) \n",
    "    \n",
    "    q_len_list = []\n",
    "    for q in questions:\n",
    "        q_len_list.append(len(q.split(\" \")))\n",
    "    q_len_mean = mean(q_len_list)\n",
    "    \n",
    "    print(\"dataset : {}\".format('gsm8k'))\n",
    "    print(\"data size : {}\".format(len(answers)))\n",
    "    print(\"average num of words for each sample : {}\".format(q_len_mean))\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afecf298-ec78-40bc-8dc8-d845abcbe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(direct_answer_trigger_for_fewshot=None, cot_flag=None):\n",
    "    x, z, y = [], [], []\n",
    "    \n",
    "    direct_answer_trigger_for_fewshot = \"The final answer is \" if direct_answer_trigger_for_fewshot is None else direct_answer_trigger_for_fewshot\n",
    "    # example sentences ...    \n",
    "    if True:\n",
    "        \n",
    "        x.append(\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\")\n",
    "        z.append(\"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6.\")\n",
    "        y.append(\"6\")\n",
    "\n",
    "        x.append(\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\")\n",
    "        z.append(\"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5.\")\n",
    "        y.append(\"5\")        \n",
    "\n",
    "        x.append(\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\")\n",
    "        z.append(\"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39.\")\n",
    "        y.append(\"39\")        \n",
    "\n",
    "        x.append(\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\")\n",
    "        z.append(\"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\")\n",
    "        y.append(\"8\")        \n",
    "\n",
    "        x.append(\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\")\n",
    "        z.append(\"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\")\n",
    "        y.append(\"9\")        \n",
    "\n",
    "        x.append(\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\")\n",
    "        z.append(\"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29.\")\n",
    "        y.append(\"29\")        \n",
    "\n",
    "        x.append(\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\")\n",
    "        z.append(\"Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls.\")\n",
    "        y.append(\"33\")        \n",
    "\n",
    "        x.append(\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\")\n",
    "        z.append(\"Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23 - 15 is 8.\")\n",
    "        y.append(\"8\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"dataset is not properly defined ...\")\n",
    "        \n",
    "    # randomize order of the examples ...\n",
    "    index_list = list(range(len(x)))\n",
    "    random.shuffle(index_list)\n",
    "\n",
    "    # Concatenate demonstration examples ...\n",
    "    demo_text = \"\"\n",
    "    for i in index_list:\n",
    "#         if cot_flag:\n",
    "        demo_text += \"\\nQuestion: \" + x[i] + \"\\n ### Answer: \" + z[i] + \"\\n####\" + \\\n",
    "                     direct_answer_trigger_for_fewshot + \" \" + y[i] + \".\\n\\n\"\n",
    "#         else:\n",
    "#             demo_text += \"Q: \" + x[i] + \"\\nA: \" + \\\n",
    "#                          args.direct_answer_trigger_for_fewshot + \" \" + y[i] + \".\\n\\n\"\n",
    "    \n",
    "    return demo_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52dab3c-632d-463b-81a9-267a346deaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_rag_questions(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        ret = []\n",
    "        for line in file:\n",
    "            # print(line)\n",
    "            json_obect = json.loads(line)\n",
    "            ret.append(json_obect)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e15bb0-aef7-47c6-aa58-65341ef7c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_data = get_rag_questions('gsm8k_rag.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7043f7d-aab0-46f2-9b50-a6dad5afbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, index=0, rag=False, rag_data=rag_data):\n",
    "    if rag:\n",
    "        prompt = \"Look at the examples below where math questions have been solved by reasoning step by step. Notice that the final answer for each question is after ####\\n\"\n",
    "        prompt += rag_data[index]['prompt']\n",
    "        prompt += '\\nSimilar to how these questions have been solved, let\\'s reason step by step and solve the following question and generate an answer. Make sure that the final numeric answers is after ### '\n",
    "        prompt += \"\\n{\\\"question\\\": \"\n",
    "        prompt += question\n",
    "        prompt += \", \\\"answer:\\\" \"\n",
    "    else:\n",
    "        prompt = \"Look at the examples below where math questions have been solved by reasoning step by step\\n\"\n",
    "        prompt += create_prompt()\n",
    "        prompt += '\\nSimilar to how these questions have been solved, let\\'s reason step by step and solve the following question and generate an answer. Make sure that the answer starts with ### Answer: '\n",
    "        prompt += \"\\nQuestion: \" + question + \"\\n### Answer: \"\n",
    "\n",
    "    # print(prompt)\n",
    "    payload = {\n",
    "        \"inputs\": \"<s>[INST] \" + prompt + \" [/INST] \",\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.6\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = predictor.predict(payload)\n",
    "    except:\n",
    "        return \"0\"\n",
    "    try:\n",
    "        answer = response[0]['generated_text']\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        answer = \"0\"\n",
    "    return answer\n",
    "\n",
    "# print(answer_question(context=\"Hi\", question=\"What is 2+2 ?\"))\n",
    "\n",
    "def extract_last_number(s):\n",
    "    # Find all sequences of digits in the string\n",
    "    if s is None:\n",
    "        return 0\n",
    "    steps = s.split('\\n')\n",
    "    for s in reversed(steps):\n",
    "        numbers = re.findall(r'\\d+', s)\n",
    "        if numbers:\n",
    "            return numbers[-1]\n",
    "    # Return the last number found, or None if no numbers are present\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23fbc34d-2ffb-498e-941f-46287ac133ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rag_data[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeb47bb7-c691-49cc-9d00-0cb17b667772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, k=100):\n",
    "    questions, answers = data_reader(dataset)\n",
    "    model_answers_no_verify = []\n",
    "    correct_answers_cnt = 0\n",
    "    for i, question in enumerate(questions[0:k]):\n",
    "        answer = float(answers[i])\n",
    "        model_long_answer = answer_question(question)\n",
    "        model_short_answer = float(extract_last_number(model_long_answer))\n",
    "        model_answers_no_verify.append({\n",
    "            'correct_answer': answer,\n",
    "            'model_short_answer': model_short_answer,\n",
    "            'model_long_answer': model_long_answer\n",
    "        })\n",
    "        correct_answers_cnt += 1 if model_short_answer == answer else 0\n",
    "        # print(model_long_answer)\n",
    "        print(model_short_answer, answer)\n",
    "        # if i % 10 == 9:\n",
    "        #     print(model_long_answer)\n",
    "        if i % 100 == 99:\n",
    "            break\n",
    "    return model_answers_no_verify, correct_answers_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83fd7d1-8538-47d4-8863-e47f858de65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write_results_to_file(filename, data):\n",
    "    # Open a file and write each dictionary as a JSON string\n",
    "    with open(filename, 'w') as file:\n",
    "        for item in data:\n",
    "            json_string = json.dumps(item)\n",
    "            # print(item)\n",
    "            # print('\\n')\n",
    "            file.write(json_string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eb01d12-7c34-45a0-bd2c-3a38d569342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_verify_1(question, rag=False):\n",
    "    prev_answer = None\n",
    "\n",
    "    for i in range(5):\n",
    "        model_long_answer = answer_question(question, rag=True)\n",
    "        model_short_answer = float(extract_last_number(model_long_answer))\n",
    "\n",
    "        if prev_answer == model_short_answer:\n",
    "            return True, model_long_answer, model_short_answer, i\n",
    "        prev_answer = model_short_answer\n",
    "\n",
    "    return False, model_long_answer, model_short_answer, 5\n",
    "\n",
    "\n",
    "\n",
    "def self_verify_2(question, rag=False):\n",
    "    prev_verification_answer = None\n",
    "    answers_dict = {}\n",
    "    for i in range(4):\n",
    "        model_long_answer = answer_question(question, rag=True)\n",
    "        model_short_answer = float(extract_last_number(model_long_answer))\n",
    "        answers_dict_ = answers_dict.get(model_short_answer, [])\n",
    "        if answers_dict_ == []:\n",
    "            answers_dict_.append(1)\n",
    "            answers_dict_.append(model_long_answer)\n",
    "        else:\n",
    "            answers_dict_[0] = answers_dict_[0] + 1\n",
    "        answers_dict[model_short_answer] = answers_dict_\n",
    "    answers_dict = {k: v for k, v in sorted(answers_dict.items(), key=lambda x:x[1][0])}\n",
    "    for k, v in answers_dict.items():\n",
    "        model_short_answer = k\n",
    "        ans_cnt = v[0]\n",
    "        model_long_answer = v[1]\n",
    "    verified = (ans_cnt >= 2)\n",
    "    return verified, model_long_answer, model_short_answer, ans_cnt\n",
    "\n",
    "def evaluate_with_self_verify_(dataset, k=100, rag=False, filename=None, strategy=1):\n",
    "    questions, answers = data_reader(data_test)\n",
    "    model_answers_verify = []\n",
    "    correct_answers_cnt, verification_confidence = 0, 0\n",
    "    for i, question in enumerate(questions[0:k]):\n",
    "        answer = float(answers[i])\n",
    "        if strategy == 1:\n",
    "            verified,  model_long_answer, model_short_answer, verify_step = self_verify_1(question, rag)\n",
    "        elif strategy == 2:\n",
    "            verified, model_long_answer, model_short_answer, ans_cnt = self_verify(question, rag)\n",
    "        dct = {\n",
    "            'number': i,\n",
    "            'verified': verified,\n",
    "            'correct_answer': answer,\n",
    "            'model_short_answer': model_short_answer,\n",
    "            'model_long_answer': model_long_answer\n",
    "        }\n",
    "        if strategy == 1:\n",
    "            dct['verify_step'] = verify_step\n",
    "        elif strategy == 2:\n",
    "             dct['ans_cnt'] = ans_cnt\n",
    "        model_answers_verify.append(dct)\n",
    "        \n",
    "            \n",
    "        correct_answers_cnt += 1 if model_short_answer == answer else 0\n",
    "        # verification_confidence += 1 if verified else 0\n",
    "        print(answer, model_short_answer, verified)\n",
    "        # filename = 'base_llama_gsm_8k_verify_100samples.json'\n",
    "        with open(filename, 'a') as file:\n",
    "            json_string = json.dumps(model_answers_verify[i])\n",
    "            file.write(json_string + '\\n')\n",
    "    return model_answers_verify, correct_answers_cnt, verification_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44663bcc-d72a-4195-b91b-1033588570b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset : gsm8k\n",
      "data size : 1319\n",
      "average num of words for each sample : 46.91357088703563\n",
      "18.0 32.0 True\n",
      "3.0 3.0 True\n",
      "70000.0 0.0 True\n",
      "540.0 540.0 False\n",
      "20.0 10.0 False\n",
      "64.0 3.0 False\n",
      "260.0 128.0 True\n",
      "160.0 67.0 True\n",
      "45.0 140.0 False\n",
      "460.0 115.0 False\n",
      "366.0 366.0 True\n",
      "694.0 803.0 False\n",
      "13.0 5.0 True\n",
      "18.0 5.0 True\n",
      "60.0 45.0 False\n",
      "125.0 125.0 True\n",
      "230.0 460.0 False\n",
      "57500.0 57500.0 True\n",
      "7.0 84.0 True\n",
      "6.0 3.0 True\n",
      "15.0 91.0 False\n",
      "14.0 48.0 False\n",
      "7.0 7.0 True\n",
      "8.0 10.0 False\n",
      "26.0 26.0 True\n",
      "2.0 5.0 True\n",
      "243.0 233.0 True\n",
      "16.0 0.0 False\n",
      "25.0 40.0 False\n",
      "104.0 5.0 True\n",
      "109.0 110.0 True\n",
      "80.0 96.0 True\n",
      "35.0 35.0 True\n",
      "70.0 140.0 True\n",
      "23.0 38.0 True\n",
      "9.0 9.0 True\n",
      "75.0 0.0 True\n",
      "2.0 2.0 False\n",
      "10.0 120.0 False\n",
      "18.0 2.0 False\n",
      "8.0 16.0 False\n",
      "200.0 200.0 True\n",
      "26.0 26.0 True\n",
      "48.0 83.0 False\n",
      "20.0 0.0 True\n",
      "104.0 56.0 False\n",
      "163.0 193.0 False\n",
      "800.0 400.0 False\n",
      "8.0 6.0 True\n",
      "30.0 39.0 False\n",
      "294.0 80.0 True\n",
      "5.0 2.0 False\n",
      "15.0 15.0 False\n",
      "40.0 380.0 False\n",
      "40.0 33.0 True\n",
      "14.0 14.0 True\n",
      "3.0 3.0 True\n",
      "83.0 3755.0 False\n",
      "57.0 0.0 True\n",
      "187.0 187.0 True\n",
      "17.0 22.0 False\n",
      "1430.0 430.0 True\n",
      "25000.0 0.0 True\n",
      "1596.0 5880.0 True\n",
      "300.0 4.0 False\n",
      "36.0 24.0 False\n",
      "48.0 44.0 True\n",
      "595.0 280.0 True\n",
      "36.0 660.0 False\n",
      "60.0 60.0 True\n",
      "7425.0 7425.0 False\n",
      "60.0 60.0 True\n",
      "221.0 221.0 True\n",
      "255.0 825.0 True\n",
      "88.0 35.0 False\n",
      "60.0 67.0 False\n",
      "5.0 800.0 False\n",
      "100.0 100.0 True\n",
      "6.0 27.0 True\n",
      "70.0 70.0 True\n",
      "10.0 14.0 True\n",
      "17.0 17.0 True\n",
      "623.0 623.0 True\n",
      "600.0 600.0 True\n",
      "15.0 11.0 False\n",
      "44.0 44.0 True\n",
      "22.0 22.0 True\n",
      "9360.0 812.0 False\n",
      "8000.0 800.0 True\n",
      "24.0 24.0 True\n",
      "225.0 135.0 False\n",
      "28.0 22.0 True\n",
      "4.0 7.0 True\n",
      "36.0 44.0 True\n",
      "348.0 180.0 True\n",
      "40.0 67.0 False\n",
      "3.0 3.0 True\n",
      "12.0 6.0 False\n",
      "5.0 20.0 False\n",
      "58.0 40.0 False\n"
     ]
    }
   ],
   "source": [
    "model_answers_verify, correct_answer_count, verification_confidence = evaluate_with_self_verify_(data_test, k=1000, rag=False, filename='llama_verify_1_rag.json')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
